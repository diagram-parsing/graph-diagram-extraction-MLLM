## ðŸ§  Abstract

Graph-structured diagrams are widely used to represent processes and relationships visually. We explore the use of a multimodal large language model (MLLM), InternVL3-14B, for information extraction from such diagrams, comparing prompting strategies and parameter-efficient fine-tuning (PEFT). Our experiments demonstrate that MLLMs can compete with traditional CV models on simple diagrams and highlight where further improvements are needed.
